@@ -0,0 +1,262 @@
idle快捷键
![快捷键]("D:\images\idle.jpg")


### 缩进
相较于以大括号区分代码块，python使用缩进 & 冒号区分代码块，好处是结构整齐，同一个级别的代码块必须相同，
### 基本数据类型
python 为动态字符类型，弱类型语言。

***数字类型***
 整型  浮点型  复数
在python中，整数可以很大，整数分为各种进制：八进制：0o开头，十六进制：0x开头
***字符串类型*** 
不可变序列，可以单引号，双引号，三引号（多行），
引号嵌套规则：单套双套三
***布尔类型***
 false none 0 0.0 复数0 空字符 ，其他为true
***类型转换***
int() 将数据转换为整数

### 基本输入 & 输出
***input()***  
input("引号里面的内容为提示输入词")
***print()***
内容里面加 . ,表示不换行输出多个内容，会自动加一个空格。
### 运算符
除法：/ & //   /正常除，//取整除
逻辑运算符：逻辑与 and  逻辑或 or  逻辑非 not 


### 流程控制
  #### 1、选择语句
if if-else 
if 表达式:  #注意冒号
    语句块 # 注意缩进

if 表达式：
    语句块1
else :
    语句块2

if 表达式：
    语句块1
elif 表达式：
    语句块2
elif 表达式
    语句块
else 
    语句块

***定义bool变量 规范的写法：if flag ;if not flag;***

#### 2、 循环
while & for 
while 条件表达式 ：     #冒号
    循环体              #缩进

for 迭代对象 in 对象：
    循环体


***range(start , end ,step)函数***包括起始值，不包括结束值,可以省略start，如果省略从零开始，可以省略step，默认为1.

推出条件
break 语句 
continue 语句
pass 空语句 不做任何事情，占位 。

### 序列
序列是一块用于存放多个值的连续内存空间 ，并且可按一定顺序排列，可以通过索引取值
***索引***：e.g:string[2],索引从零开始的，索引可以为复数，切片似乎是切片的特殊情况
***切片***：sname[start : end :step]，省略第一个参数冒号不能掉。
***序列相加*** 只能是同类型的序列相加，列表+列表；元组+ 元组；
***序列数乘*** 表示将序列重复多少遍，输出10个 * ;-->**10
***检查是否为序列成员***   待检验元素 in 序列-------》返回值为bool，若想确定是否不在：not in，俩个关键字
***计算序列长度***  len(待检测序列)，max(待检测序列),返回最大值，min(待检测序列),返回最小值，但都用在元素为数据类型，list(待检测序列),str(),sum()'''''''

### 列表
列表--》可变数列
***创建列表*** 1.使用赋值运算符直接创建： e.g: listname = [1,2,3,4,5]     2.创建空列表：e.g: emptylist = []         3.创建数值列表 ：e.g: list()函数   
***删除列表*** del listname ,python 自带垃圾回收机制会自动销毁，不必手动删除
***访问列表*** listname[2], 遍历：1 .for循环， 2. enumerate()函数，可以输入index 索引
***改动列表*** append()方法，列表1.append(新元素)  ，insert(0,内容)  ，listname.extend(seq) .


### 元组
***创建 & 删除*** name = (a,b,c,d,),若 name = { a},则非元组，想创建一个元素的元组，a = (a,)   加逗号。创建空元组：name = (),创建数值元组：tuple（）函数
***访问元组***  name[1],/name[start,end,step]

**元组 & 列表的区别**  ，元组 不可变数列，列表 可变数列 ，元组的访问速度快，可以作为字典的键。

***字典*** 
**创建 & 删除** 
```python
#dictionary = {'key1':'value1','key2':'value2'}      #按照键值对的形式来的，类比于新华字典
word = {1:hello,2:你好,3：萨瓦迪卡， 4:空你几哇}    #   只知道这几个国家了，
print(word)

```
**键值对访问**
```python
dictionary.get(key,[defeat 默认值，若没有就显示默认值])
dictionary[key]
```

***施工中还在学***

### 面向对象编程 oop



对象 类 封装 继承 多态
***类的使用***
**定义类** 类名：驼峰命名 
```python
class ClassName :               # 冒号别掉了
    ''' 类的帮助信息 '''
    类体（如果没想好些什么，pass 语句）
```

**创建类的实例**
**创建对象**
创建的实例名 = 类名(可选参数，__init__()方法的参数)   

创建 __init__(self)方法（构造方法），def __init__(self)  ,self 必须要有，但是可以用其他的代替，只是需要一个参数。

***创建类的成员并访问***  实例方法 --方法 ，数据成员 --属性 。 
1. 实例方法
```python
def function(self,others)
```
2. 数据成员 ：类属性 & 实例属性
类属性在所有方法通用，实例属性--定义在当前实例中，只能当前方法使用

**访问限制**
什么都不加，（public） ， __foo （private） ，__foo__ （系统）-------》私有，不能实例名访问，类本身可以访问，类的实例名.类名_xxx访问


面向对象的三大特性：
- 封装：(专业话)把客观事物抽象成类，并且把自己的属性和方法让可信的类或对象操作，对不可性的隐藏。
- 继承：（专）它可以使用现有类的所有功能，并在无需重新编写原来的类的情况下对这些功能进行扩展。（简单说）应该就代码的重复利用，可扩展，但其实还有很多讲究
- 多态：（专）允许你将父对象设置成为和一个或更多的他的子对象相等的技术，赋值之后，父对象就可以根据当前赋值给它的子对象的特性以不同的方式运作。这就意味着虽然针对不同对象的具体操作不同，但通过一个公共的类，它们（那些操作）可以通过相同的方式予以调用。




### 文件操作
***基本文件操作***
创建，打开，读取，写入，关闭，
open(),

**创建 & 打开** 
open(filename,mode,读写模式的缓存模式)，后两个可选。open函数返回值为文件对象。
r w a;可以与加号组合，也可以与b组合，表示二进制
**关闭**
 file.close()方法；文件对象的close方法；验证是否打开 ，file.closed 返回是否关闭
**with语句** 
with expression as target:
                blocks
可以时时关闭文件
**读取文件**
读取指定字符:file.read(要读取的字符个数，默认为全部)，要求文件必须为  r /r+；
读取一行；file.readline r/r+ only; 
读取全部行：file.readlines ,其返回值为字符串列表。

### 目录操作
os /os.path python内置模块
**路径知识**：
1.相对路径指从当前目录到目标目录的路径，
2.绝对路径指从顶级目录到目标目录的路径。
在python中：

```python
import os
os.name #若返回nt则为windows
getcwd #查看当前工作目录
'''
若路劲要 '/',由于python中/为转移字符，一般\ huozhe //
'''
os.path.abpath()   #获取绝对路径

```
**判断目录是否存在**
```python
os.path.exists(path)        #返回bool，也可判断文件存在
```
**创建目录**
```python
os.mkdir(path,mode=0o777)   #第二个指定数值模式，默认的 ，不进行修改
os.rmdir(path) #删除目录
```
**dos常见指令**
 1. dir查看当前目录有什么内容
 2. cd 切换到其他盘或切换到当前盘其他目录，切换到上级目录cd ..,直接上天cd\;
 3. tree 建立目录树，
 4. 清屏，cls
 5. exit 推出dos
 6. md 创建目录，rd删除目录，copy 拷贝文件，del删除文件，echo输入文件到内容，move剪切e.g:echo hello > hello.txt



### 爬虫学习
网络爬虫就是自动抓取网页信息的代码，可以简单理解成代替繁琐的复制粘贴操作的手段。
request模块 :python 中原生的一款基于网络请求的模块，功能强大，**用于模拟浏览器发请求**
使用：
 - 指定Url
 - 发起请求
 - 获取响应
 - 持久化存储
  
更具体完整的
- 导入两个库，一个用于请求，一个用于网页解析
- 请求网页，获得源代码
- 初始化soup对象，使其可以调用更简单易用的方法
- 用浏览器打开网页，右键-检查，使用那个鼠标定位你要找的资源的位置
- 分析那个位置的源代码，找到合适的用于定位的标签及属性
  编写解析代码，获得想要的资源

第一个爬虫文件：
```python
import requests     #导入request包

if __name__ == "__main__":
    url = 'http://www.sogou.com/'       #url
    response = requests.get(url=url)        #发送请求
    page_text = response.text       
    print(page_text)
    with open('./sogou.html', 'w', encoding='utf-8') as fp:
        print("over")

```
主要学习requests库来做爬虫：
import requests
headers = {'User-Agent':"Mozilla/5.0(Windows NT 6.1;WOW64)AppleWebkit/537.36(......)}      #伪装成普通浏览器去骗数据，

1. get请求
   最常用的：get post pit delete option 
```python
    response = requests.get(url=url)        #发送请求
    print(response.text)
    

```




常见请求头的含义：（cv的）
Accept:text/html,image/*[告诉服务器，浏览器可以接受文本，网页图片]
Accept-Charaset:ISO-8859-1 [接受字符编码：iso-8859-1]
Accept-Encoding:gzip,compress[可以接受 gzip,compress压缩后数据]
Accept-Language:zh-cn[浏览器支持的语言]
Host:localhost:8080[浏览器要找的主机]
IF-MODIFIED-Since:Tue,11Jul 2000 18:23:51[告诉服务器这缓存中有这个文件,该文件的时间是...]
Referer:http://localhost:8080/test/abc.html[告诉服务器来自哪里]
User-Agent:Nozilla/4.0(Com...)[告诉服务器浏览器内核]
Cookie：[HTTP请求发送时，会把保存在该请求域名下的所有cookie值一起发送给web服务器。]
Connection:close/Keep-Alive [保持链接，发完数据后，不关闭链接]
Date:[浏览器发送数据的请求时间]


